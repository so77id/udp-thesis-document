\chapter[Algoritmo propuesto]{Algoritmo propuesto}
\label{ch:algoritmo}
\section{Pipeline}
\label{sec:pipeline}
Para poder solucionar el problema propuesto en la Sección~\ref{sec:problema}, se propone un algoritmo compuesto por cuatro módulos. \emph{Preprocesamiento de la base de datos}, módulo encargado de quitar todo el ruido de los vídeos de entrenamiento, \emph{extracción de micro-descriptores}, encargado de dividir el video en distintas regiones de interés para crear un micro-descriptor basado en el movimiento interno de éstas, \emph{creación de macro-descriptores}, toma los micro-descriptores y crea un nuevo macro-descriptor por vídeo utilizando técnicas de \textit{clustering}, y por último \emph{entrenamiento y clasificación}, encargado de crear un modelo de clasificación con los descriptores de entrenamiento, para luego utilizar este modelo para la posterior clasificación de nuevos vídeos. Presentamos este modelo en la Figura~\ref{algoritmo:fig:pipeline}, donde podemos visualizar la arquitectura básica de un sistema de reconocimiento de patrones, siendo la adquisición de datos representada por el preprocesamiento de la base de datos, la extracción de características es reemplazada por la extracción de micro-descriptores y la creación de macro-descriptores, y finalmente la etapa de clasificación es el entrenamiento y clasificación de nuestro pipeline.

	\begin{figure}[bt]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/pipeline.png}
  		\caption{Pipeline del algoritmo propuesto.}
  		\label{algoritmo:fig:pipeline}
	\end{figure}	


\section{Preprocesamiento de la base de datos}
\label{sec:proc_bdd}
	El preprocesamiento de la base de datos es la etapa donde se realiza la limpieza de todos los datos que entran al algoritmo. Cada uno de los vídeos de entrada tienen elementos que no aportan mayor información al método, sino que también pueden aportar ruido, de tal manera se procede a eliminar todos estos elementos. Este procedimiento se divide en dos etapas: \emph{cetección de rostros}, que utiliza el algoritmo de Viola-Jones para encontrar el rostro del primer cuadro, y el segundo \emph{corrección de movimiento}, que utiliza el cuadro encontrado del rostro para corregir el movimiento de todos los cuadros del vídeo. Este procedimiento puede ser visualizado en la Figura~\ref{algoritmo:fig:preprocesamiento}. 
	
	\begin{figure}[tb]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/Preprocesamiento.png}
  		\caption{Diagrama del preprocesamiento de los datos.}
  		\label{algoritmo:fig:preprocesamiento}
	\end{figure}	

	
	\subsection{Detección de rostros}
	\label{algoritmo:det_rostro}
	Para cada uno de los vídeos que se utilizarán en el algoritmo es necesario quitar todos los elementos que no aportan información. De tal forma, utilizamos un algoritmo de detección de rostros, el cual obtiene los vértices del rectángulo que encierra la cara en el primer cuadro. Utilizaremos este rectángulo en la fase de corrección de movimiento del rostro. 
		
	\subsection{Corrección de movimiento}
	\label{algoritmo:cor_movimiento}
	Luego de realizar la detección de rostros para cada uno de los cuadros del vídeo, se procede a realizar la corrección del movimiento rígido. Ésta consiste en realizar operaciones de translación y rotación sobre cada uno de los cuadros del vídeo utilizando la imagen del rostro detectado en el primer cuadro como modelo para ajustar los cuadros siguientes.


\section{Extracción de micro-descriptores}
\label{sec:micro_descriptores}
	El proceso de extracción de micro-descriptores es el núcleo del algoritmo. Este proceso es el encargado de la extracción de características directas del vídeo o imagen dinámica. Para esto se introduce un nuevo término que es denominado \textit{Rayo de flujo} o simplemente \textit{Rayo}. Éste define el movimiento de los píxeles dentro las regiones de interés (ROI por sus siglas en inglés) en los cuadros del vídeo. Esta etapa se puede dividir en tres grandes bloques, primero, la \emph{codificación}, etapa en la cual el video puede ser codificado utilizando técnicas como LBP o LDN\@. Esta etapa es opcional y será mayormente profundizada en el Capítulo~\ref{ch:exp_result}. Segundo, \emph{extracción de rayos}, la cual consiste en determinar las regiones de interés de donde se extraerán los \textit{Rayos de flujo}, y su extracción como tal. Y por último, \emph{normalización}, esta etapa se encarga de llevar todos los \textit{Rayos} al mismo espacio vectorial, dado un tamaño fijo. Un diagrama de la extracción de micro-descriptores puede ser visto en la Figura~\ref{algoritmo:fig:micro_descriptores}.

\afterpage{% corrige el breakpage
\begin{landscape}
	\begin{figure}[t]
		\centering
    		\includegraphics[width=\linewidth]{Figuras/Diagramas/Extractor_microdescriptores}
  		\caption{Diagrama general del proceso de extracción de micro-des\-crip\-to\-res.}
  		\label{algoritmo:fig:micro_descriptores}
	\end{figure}	
\end{landscape}}

	\subsection{Elección de regiones de interés}
	\label{algoritmo:elecc_roi}
	De cada video que se quiere procesar, después de realizar el preprocesamiento definido en la Sección~\ref{sec:proc_bdd}, se seleccionan las regiones de interés a las cuales se les extraerá los \textit{Rayos}. Las áreas se seleccionarán utilizando distintos criterios [$\mathds{R}(\cdot)$, ver (\ref{algoritmo:eq:roi})], por ejemplo, pueden utilizarse áreas puntuales con alta expresividad (\eg, los ojos, la boca, la nariz, \etc), o bien áreas generales (\eg, todo el rostro).
	
	De tal forma, definimos un video como 
	\begin{equation}\label{algoritmo:eq:video}		
		V = \{\text{ROI}_i | 1 \leq i \le I\}, 
	\end{equation}
	donde $I$ es el número de regiones de interés en el vídeo. Y además, definimos el $i$-ésimo ROI, $\text{ROI}_i^t$, como el conjunto de píxeles $(x,y)$ para un determinado cuadro $t$, tal que
	\begin{equation}\label{algoritmo:eq:roi}
		\text{ROI}_{i}^{t} = \{(x,y) | (x,y,t) \in \mathds{R}(i)\},
	\end{equation}
	donde $\mathds{R}(i)$, es una función que devuelve la $i$-ésima región en que dividimos el vídeo, según el criterio antes mencionado.

	\subsection{Extracción de rayos}
	\label{algoritmo:ext_rayos}
	
	Para esta sección se introducen dos términos nuevos: la \textit{región de soporte} y la \textit{ventana de búsqueda}. La \textit{región de soporte} es utilizada para calcular el movimiento del píxel central con respecto al cuadro siguiente. Similarmente, la \textit{ventana de búsqueda} es el espacio supuesto en el cual se pudo haber desplazado la región de soporte en el siguiente cuadro, y por ende, donde lo buscaremos. Definimos estos términos formalmente a continuación.
	
	\begin{definition}[Región de soporte]	
  Dado un píxel $(x,y)$ en un cuadro $t$, definimos una región de soporte RS, de tamaño $R \times R$ (donde $R$ es impar), como la subregión del cuadro $t$ que está centrada en el píxel $(x,y)$.
	\end{definition}

	\begin{definition}[Ventana de búsqueda]
	Dado un píxel $(x,y)$ en un cuadro $t$, definimos la ventana de búsqueda WS, de  tamaño $W \times W$(donde $W < R$ y $W$ es impar), como la subregión del cuadro $t+1$ que está centrada en el píxel $(x,y)$.
	\end{definition}
		
	Dado un píxel $(x,y)$ en el cuadro $t$, la extracción de rayos consiste en obtener una \textit{región de soporte}, $\text{RS}(x,y,t)$, una \textit{ventana de búsqueda}, $\text{WS}(x,y,t)$, y encontrar la posición de mejor emparejamiento entre la \textit{región de soporte} y la \textit{ventana de búsqueda}. Esta búsqueda se realiza calculando el error Cuadrático Medio (MSE por sus siglas en inglés), \begin{equation}\label{algoritmo:eq:mse}	
			\text{MSE}(\text{RS}, \text{RS}') = \sum_{x=1}^{R} \sum_{y=1}^{R} \left(\text{RS}(x,y,t) - \text{RS}'(x',y', t+1)\right)^2,
		\end{equation} 
	donde $\text{RS} = \text{RS}(x,y,t)$ es la \textit{región de soporte} del píxel $(x,y)$ en el cuadro $t$, al que esta extrayendo el \textit{rayo}, y $\text{RS}' = \text{RS}'(x',y',t+1) \in \text{WS}(x,y,t)$ es una subregión de la \textit{ventana de búsqueda} del píxel $(x,y)$ en el cuadro $t+1$ de tamaño $R$ (note que la \textit{ventana de búsqueda} del píxel $(x,y)$ en el cuadro $t$ está definida en el cuadro $t+1$).
		
	Esta operación se realiza para cada uno de los desplazamientos que puedan ser realizados por la \textit{región de soporte} dentro de la \textit{ventana de búsqueda}. De tal forma que buscamos la posición de la región $\text{RS}'$ que minimiza el MSE respecto de la \textit{región de soporte} del píxel $(x,y)$ en el cuadro $t$, $\text{RS}(x,y,t)$, de tal forma que la región $\text{RS}'$ óptima será
	\begin{equation}
		\text{RS}^* = \arg \min_{\text{RS}'}\{\text{MSE}(\text{RS},\text{RS}') | \text{RS}' \in \text{WS} \},
	\end{equation}		
	 la cual será la región $\text{RS}'$ donde el error sea mínimo, con lo que se puede deducir que la región $\text{RS}$ se desplazó a la región $\text{RS}^*$ en el tiempo $t+1$. Mediante esto se obtiene el píxel $(x^*,y^*)$ que corresponde al centro de la ventana obtenida en el proceso anterior, $\text{RS}^*$.
	
	Para calcular el desplazamiento en el cuadro $t$ de $(x,y)$ a $(x^*,y^*)$, se procede a realizar la resta de los ejes. De tal forma que
	\begin{align}
		\Delta x^{t} &= x^*-x,\\ 
		\Delta y^{t} &= y^*-y,
	\end{align}
		donde $ \Delta x^t$ y $ \Delta y^t$ son componentes del \textit{Rayo de soporte}. Definimos un \textit{Rayo de soporte} como:
	
	\begin{definition}[Rayo de soporte]
		Dado un par ordenado $(x,y)$ en el tiempo $t$, el \textit{Rayo de soporte} para dicho píxel esta definido por el nuevo par ordenado $(\Delta x^{t}, \Delta y^{t})$, de tal forma que,
		\begin{equation}
			\rho_{(x,y)} = \{(\Delta x^{t}, \Delta y^{t})~| \forall t\}.
		\end{equation}		
	\end{definition}	
		
	Los \textit{Rayos de soporte} son la estructura básica de los \textit{Rayos de flujo}, dado que al juntar todos los desplazamientos del píxel $(x,y)$ a lo largo de los cuadros del vídeo, se obtiene un conjunto de variaciones de movimientos. En palabras más formales, se define:
	
	\begin{definition}[Rayo de flujo]	
		Es el conjunto de \textit{Rayos de soporte} que representan el movimiento del píxel $(x,y)$ en cada uno de los cuadros $t$, este conjunto es definido como \textit{Rayo de flujo} o micro-descriptor, de tal forma que,
			\begin{equation}
				R(x,y)	 = \{\rho_{(x,y)}, \rho_{(x^*,y^*)}, \rho_{(x^{**},y^{**})}, ... \},
			\end{equation}
		donde ($x^{**}$,$y^{**}$) es el píxel al cual se desplazo ($x^{*}$,$y^{*}$) en el cuadro $t+2$. El desplazamiento de los \textit{rayos} puede ser visto en la Figura~\ref{algoritmo:fig:extraccion}.
	\end{definition}
	
	\begin{figure}[bt]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/Extraccion_de_rayos.png}
  		\caption{Representación de la extracción de rayos de un vídeo.}
  		\label{algoritmo:fig:extraccion}
	\end{figure}	

	
		
		
	\subsection{Normalización de rayos}
	\label{algoritmo:normalizacion}
	Luego de obtener el total de micro-descriptores es necesario poder llevar todos los \textit{rayos} al mismo espacio vectorial, esto debido a que el tamaño de cada conjunto depende de la cantidad de cuadros $T$ del vídeo. Para este proceso se introduce una variable muy importante para el algoritmo llamada $N$, esta sera la encargada de comandar el proceso de normalización, de tal forma que se obtiene una razón de normalización
	\begin{equation}
		Rn = \frac{T}{N},
	\end{equation}
	está permite relacionar la cantidad de \textit{Rayos de soporte} $\rho$ del \textit{Rayo} $R(x,y)$ original que formarán parte de los $\rho'$ de $R(x,y)'$ normalizado. Este proceso puede ser visualizado en la Figura~\ref{algoritmo:fig:normalizacion}.
	
	\begin{figure}[bt]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/normalizacion_de_rayos.png}
  		\caption{Normalización de rayos.}
  		\label{algoritmo:fig:normalizacion}
	\end{figure}	

	
\newpage	
\section{Creación de macro-descriptores}
\label{sec:macro-descriptores}
El proceso de creación de macro-descriptores es el proceso final de la extracción de características de los videos. Luego de obtener un extenso conjunto de \textit{Rayos} para cada uno de los videos, es necesario poder crear grupos de \textit{Rayos}, los cuales puedan representar de mejor manera el espacio ya normalizado. Para esto se utilizan técnicas de \textit{clustering}. El proceso de creación de macro-descriptores puede ser visto en las Figuras~\ref{algoritmo:fig:macro_descriptores:entrenamiento} y~\ref{algoritmo:fig:macro_descriptores:clasificacion}

	\begin{figure}[bt]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/Extractor_macrodescriptores_entrenamiento.png}
  		\caption{Proceso de creación de macro-descriptores en la fase de entrenamiento.}
  		\label{algoritmo:fig:macro_descriptores:entrenamiento}
	\end{figure}	
	
	
	\begin{figure}[bt]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/Extractor_macrodescriptores_clasificacion.png}
  		\caption{Proceso de creación de macro-descriptores en la fase de clasificación.}
  		\label{algoritmo:fig:macro_descriptores:clasificacion}
	\end{figure}	



	\subsection{Bag of Visual Words}
	\label{algoritmo:bow}
		Esta es una técnica dependiente de la cantidad $K$ de palabras que se introduzcan a la bolsa. Como se puede observar en la Figura~\ref{algoritmo:fig:bow}, esta técnica permite armar $K$ grupos representados por un centroide o \textit{cluster} llamado $C_k$. Estos \textit{clusters} son los puntos de referencia de cada uno de estos grupos. Para saber a cual de los $K$ centroides pertenece un \textit{Rayo} $R(x,y)$, es necesario calcular el
		\begin{equation}
  			\label{algoritmo:eq:dist}
			k^* = \arg \min_k \{\mathit{d}(R(x,y),C_k)\},
		\end{equation}
		donde la función $\mathit{d}(\cdot,\cdot)$ representa la distancia euclidiana 
		\begin{equation}
		 d(x,y) = \Big\{\sum_{i} (x_i-y_i)^2\Big\}^{1/2} 
		\end{equation}
		

	\begin{figure}[tb]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/bow_solo.png}
  		\caption{Construcción del Bag of Words.}
  		\label{algoritmo:fig:bow}
	\end{figure}	

	\subsection{Creación de macro-descriptores}
	\label{algoritmo:crea_macro-descriptores}
	Luego de tener etiquetado cada uno de los \textit{Rayos} $R(x,y)$ con su centroide respectivo, se procede a crear el macro-descriptor de cada uno de los vídeos.	 Esto se realiza creando un histograma de tamaño $K$ para cada uno de las regiones de interés ${ROI}_{i}^{t}$ del vídeo, de tal forma que en este histograma se tenga presente la frecuencia de cada uno de los \textit{clusters} encontrados en la creación del \textit{Bag of Visual Words}. Con esto presente, definimos el descriptor $D_i$ de la región de interés $\text{ROI}_i$ como
	\begin{align}
		\label{algoritmo:eq:hist}
		D_i(k) &= \sum_{(x,y)\in \text{ROI}_i} \delta (R(x,y),k), \quad \forall k,\\
		\label{algoritmo:eq:fun_hist}
		 \delta (R(x,y),k) &= \begin{cases}
		 1 & \mbox{si }R(x,y)~\in~C_k\\
     0 & \text{otro caso}
     \end{cases},
	\end{align}
de tal forma que $\delta(\cdot,\cdot)$ es una función que cuenta los rayos pertenecientes al \textit{cluster} $k$, $C_k$.

	\begin{figure}[bt]
		\centering
		\includegraphics[width=1\textwidth]{Figuras/Diagramas/macro-descriptor.png}
		\caption{Construcción del macro-descriptor.}
		\label{algoritmo:fig:macrodescriptores}
	\end{figure}	

	Luego de obtener dichos descriptores por región, se procede a concatenar cada uno de los histogramas pertenecientes al mismo vídeo de la siguiente forma
	\begin{equation}
		\mathds{D} = \cat_{i = 1}^{I} D_i, \quad \forall i,
	\end{equation}	   
   donde $\cat$ es el operador de concatenación de los vectores $D_i$. Este proceso puede ser visto en la Figura~\ref{algoritmo:fig:macrodescriptores}. El resultado de esta concatenación es el macro-descriptor del video seleccionado.
   


	En el proceso clasificación, no se recalculan los centroides para un nuevo vídeo, ya que, se guarda el modelo que contiene el resultado del \textit{Bag of Visual Words}, y se procede a calcular~(\ref{algoritmo:eq:dist}), formula que permite saber cual es el \textit{cluster} mas cercano para cada uno de los \textit{Rayos} $R(x,y)$ obtenidos en el proceso de extracción de micro-descriptores. Luego de esto al igual que en el proceso de entrenamiento se crea el macro-descriptor con el mismo método.
	
	
\section{Entrenamiento y clasificación}
\label{sec:clasificacion}
El entrenamiento y clasificación es la etapa del algoritmo que se dedicada a la segmentación del espacio vectorial formado por los macro-descriptores. Para este proceso se utilizarán las \textit{Support Vector Machines}, explicadas en la Sección~\ref{sec:rec_patrones}. Estás se utilizan para entrenar el modelo que luego es utilizado para clasificar las nuevas entradas de vídeo. 
Para poder probar la efectividad del clasificador se utilizaran técnicas de validación cruzada ($k$\textit{-fold~cross-validation} en inglés). Esta técnica consiste en dividir el conjunto de datos en dos grupos, uno de entrenamiento y uno de prueba, $k$ veces. Esta técnica es utilizada para correr el algoritmo en distintas instancias, y así poder obtener un valor más real de la asertividad (\textit{Accuracy}). Se mostrarán los resultados de esta técnica en la Capítulo~\ref{ch:exp_result}.

	\begin{figure}[bt]
		\centering
    		\includegraphics[width=0.7\textwidth]{Figuras/Diagramas/Entrenamiento.png}
  		\caption{Entrenamiento del clasificador.}
  		\label{algoritmo:fig:entrenamiento}
	\end{figure}	
	
	\begin{figure}[bt]
		\centering
    		\includegraphics[width=0.7\textwidth]{Figuras/Diagramas/Clasificacion.png}
  		\caption{Clasificador utilizando el modelo creado para clasificar nuevas entradas.}
  		\label{algoritmo:fig:clasificacion}
	\end{figure}	
		
	


	\subsection{Entrenamiento}
	\label{algoritmo:entrenamiento}
		Luego de que el conjunto de datos de entrenamiento pasa por todas las etapas anteriores del algoritmo, se tiene para cada uno de los vídeos un macro-descriptor compuesto por la concatenación de los histogramas de de cada una de las regiones de interés y una etiqueta que indica a que clase pertenecen. Este conjunto de descriptores y las etiquetas son utilizados por las \textit{Support Vector Machines} para la creación de un modelo de clasificación, el que permite poder etiquetar nuevas entradas, este proceso puede ser visto en la Figura~\ref{algoritmo:fig:entrenamiento}.
	
	Las \textit{Support Vector Machines}, son un clasificador de dos clases, entonces es necesario utilizar técnicas que permita realizar la clasificación utilizando muchas clases. Para el caso de esta implementación es necesario poder generar un modelo que permita clasificar las seis expresiones universales. Con este motivo se utiliza la técnica ``\textit{Uno contra uno}'', la cual consiste en generar $C(C-1)/2$ clasificadores, donde cada clase tiene una barrera de decisión asociada a cada una de las demás clases. Esto permite que la región de incertidumbre formada por las barreras de decisión sea mínima.
			
		
	\subsection{Clasificación}
	\label{algoritmo:clasificacion}
		Ya teniendo el modelo resultante de la etapa de entrenamiento, esté es utilizado para la clasificación de nuevas entradas sin etiquetar, esto con la misión de poder asignar una etiqueta al nuevo descriptor, este proceso puede ser visto en la Figura~\ref{algoritmo:fig:clasificacion}. En esta etapa se puede medir cual es la precisión del algoritmo, esta medición sera mayormente abordada en el Capítulo~\ref{ch:exp_result}.
		
	
	
	
	
	