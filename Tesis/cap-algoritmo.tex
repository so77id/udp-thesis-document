\chapter[Algoritmo]{Algoritmo}
\label{ch:algoritmo}
\section{Pipeline}
\label{sec:pipeline}
Para poder solucionar el problema propuesto en la Sección~\ref{sec:problema}, se propone un algoritmo compuesto por cuatro módulos. \textbf{Preprocesamiento de la base de datos:} modulo encargado de quitar todo el ruido de los vídeos de entrenamiento, \textbf{Extracción de micro-descriptores:} encargado de dividir el vídeo en distintas regiones de interés, para crear un micro-descriptor basado en el movimiento interno de estas, \textbf{Creación de macro-descriptores:} toma los micro-descriptores y crea un nuevo macro-descriptor por vídeo utilizando distintas técnicas y por ultimo \textbf{Entrenamiento y clasificación:} encargado de crear un modelo de clasificación con los descriptores de entrenamiento, para luego utilizar este modelo para la posterior clasificación de nuevos vídeos. Este proceso puede ser visto en la Figura~\ref{algoritmo:fig:pipeline}. 

	\begin{figure}[bt]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/pipeline.png}
  		\caption{Pipeline del algoritmo propuesto.}
  		\label{algoritmo:fig:pipeline}
	\end{figure}	


\section{Preprocesamiento de la base de datos}
\label{sec:proc_bdd}
	En esta etapa se procede a realizar la limpieza de todos los datos que entran al algoritmo. Dado que para el conjunto de datos de entrenamiento estamos utilizando una base de datos de vídeos (hacer referencias y hablar un poco de la BDD ya que se va hablar mas en los experimentos). Cada uno de estos vídeos de entrada tienen elementos que no aportan mayor información al método, sino que también pueden aportar ruido, de tal manera se procede a eliminar todos elementos. Para este procedimiento se divide en dos etapas: \textbf{Detección de rostros:} Utiliza el algoritmo de Viola-Jones para encontrar el rostro del primer cuadro, y segundo \textbf{Corrección de movimiento:} utiliza el cuadro encontrado del rostro para corregir el movimiento de todos los cuadros del vídeo. Este procedimiento puede ser visualizado en la Figura~\ref{algoritmo:fig:preprocesamiento}. 	
	
	\begin{figure}[tb]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/Preprocesamiento.png}
  		\caption{Diagrama del preprocesamiento de los datos.}
  		\label{algoritmo:fig:preprocesamiento}
	\end{figure}	

	
	\subsection{Detección de rostros}
	\label{algoritmo:det_rostro}
	Para cada uno de los vídeo que se requieran utilizar en el algoritmo es necesario quitar todos los elementos que no aporten información. Para realizar esta tarea primero es necesario utilizar un algoritmo de detección de rostros, que nos permita obtener los vértices del rectángulo que encierra la cara en el primer cuadro. Este rectángulo sera utilizado para la fase de corrección de movimiento como el modelo para centrar todos los cuadros del vídeo.	
		
	\subsection{Corrección de movimiento}
	\label{algoritmo:cor_movimiento}
	Luego de realizar la detección de rostros para cada uno de los cuadros del vídeo, se procede a realizar la corrección del movimiento rígida, la cual consiste en realizar operaciones de translación y rotación sobre cada uno de los cuadros del vídeo, utilizando la imagen del rostro detectado en el primer cuadro como modelo para poder ajustar los cuadros siguientes.


\section{Extracción de micro-descriptores}
\label{sec:micro-descriptores}
		El proceso de extracción de micro-descriptores es el núcleo del algoritmo. Este proceso es el encargado de la extracción de características directas del vídeo o imagen dinámica. Para esto se introduce un nuevo término que es denominado ``Rayo de flujo'' o simplemente ``Rayo''. Éste define cual es el movimiento de las regiones de interés (ROI sus siglas en inglés) en los cuadros del vídeo. Esta etapa se puede dividir en tres grandes bloques, primero \textbf{Codificación:} etapa en la cual el vídeo puede ser codificado utilizando técnicas como LBP o LDN. Esta etapa es opcional y sera mayormente profundizada en el Capitulo~\ref{ch:exp_result}, segundo \textbf{Extracción de rayos:} consiste en determinar las regiones de interés a las cuales se extraerán los ``Rayos de flujo'', y su posterior extracción. Y por ultimo \textbf{Normalización:} Esta etapa se encarga de llevar todos los ``Rayos de flujo'' al mismo espacio vectorial. Un diagrama de la Extracción de micro-descriptores puede ser visto en la Figura~\ref{algoritmo:fig:micro_descriptores}.

	\begin{figure}[tb]
		\centering
    		\includegraphics[width=1\textwidth,angle=90]{Figuras/Diagramas/Extractor_microdescriptores.png}
  		\caption{Diagrama general del proceso de extracción de micro-des\-crip\-to\-res.}
  		\label{algoritmo:fig:micro_descriptores}
	\end{figure}	


	\subsection{Elección de regiones de interés}
	\label{algoritmo:elecc_roi}
	Para cada uno de los vídeos que se quiere procesar, después de realizar el preprocesamiento definido en la Sección~\ref{sec:proc_bdd}, se seleccionan las regiones de interés a las cuales se les extrae los ``Rayos''. Las áreas son seleccionadas dependiendo la cantidad de información que entregan. 
	
	Definimos un vídeo como 
	\begin{equation}\label{algoritmo:eq:video}		
		V = \{\text{ROI}_i | 1 \leq i \le I\}, 
	\end{equation}
	donde $I$ es el número de regiones de interés en el vídeo.
	
	Definimos un ROI, $\text{ROI}_i$ como el conjunto de voxels (un voxel es una tripleta o un píxel en 3D), tal que
	\begin{equation}\label{algoritmo:eq:roi}
		\text{ROI}_{i}^{t} = \{(x,y) | (x,y,t) \in \mathds{R}(i)\},
	\end{equation}
	Donde $\mathds{R}(i)$, es una función que devuelve la $i$-esima región en que dividimos la imagen.

	\subsection{Extracción de rayos}
	\label{algoritmo:ext_rayos}
	
	Para esta sección se introducen dos términos, la región de soporte y ventana de búsqueda.
	La región de soporte es utilizada para calcular el movimiento del píxel central con respecto al cuadro siguiente. A su vez la ventana de búsqueda tiene como objetivo generar un espacio supuesto en el cual se puede haber desplazado la región de soporte en el siguiente cuadro.
	
	\begin{definition}[Región de soporte]	
	{Región de soporte.} Dado un píxel (x,y) en un cuadro t, existe una subregión cuadrada de tamaño $L$ (donde $L$ es impar) que esta centrada en dicho píxel, y además es subconjunto de $\text{ROI}_i^t$ tal que:
		\begin{equation}
			\text{RS}(x,y,t) := \{\text{RS} \subseteq \text{ROI}_i^t | (x,y,t) \in \text{ROI}_i^t \} 
		\end{equation}
	
	
%	es una sección de la ROI la cual es de tamaño $T$, donde $T$ es impar y esta centrada en el píxel $(x,y)$ en el cuadro $t$ del vídeo. Esta región es utilizada para calcular el movimiento de dicho píxel con respecto al cuadro $t+1$.
	\end{definition}

	\begin{definition}[Ventana de búsqueda]
	{Ventana de búsqueda.} Dado un píxel (x,y) en un cuadro t+1, existe una subregion cuadrada de tamaño $2L+1$ que esta centrada en dicho píxel, y ademas es subconjunto de $\text{ROI}_{i}^{t+1}$ tal que:
	\begin{equation}
		\text{WS}(x,y,t) := \{\text{WS} \subseteq \text{ROI}_{i}^{t+1} | (x,y,t+1) \in \text{ROI}_{i}^{t+1} \} 
	\end{equation}
	
	%al igual que la región de soporte es una sección del ROI de tamaño $2T+1$ y centrada en el píxel $(x,y)$, pero a diferencia de la anterior, esta se extrae del cuadro $t+1$. El objetivo de esta ventana es generar un espacio supuesto, donde se puede haber desplazo la región de soporte.
	\end{definition}
		
	La extracción de rayos consiste en que para cada píxel de la región de interés, se obtenga una región de soporte en cada cuadro y esta sea buscada dentro de la ventana de búsqueda del cuadro siguiente. Esta búsqueda se realiza calculando el error Cuadrático Medio o MSE (por sus siglas en ingles), \begin{equation}\label{algoritmo:eq:mse}	
			MSE(\mathit{RS},\mathit{RS'}) = \sum_{x=1}^{L} \sum_{y=1}^{L} (\mathit{RS}(x,y) - \mathit{RS'}(x,y))^2,
		\end{equation} 
	donde RS es la region de soporte del píxel (x,y) en el cuadro t, al que esta extrayendo el rayo, y RS' es una subregion de WS de tamaño $L$.
		
	Notemos que esta operacion se realiza para cada uno de los desplazamientos que se puedan realizar de la región de soporte sobre la de búsqueda. Luego de calcular el MSE de cada píxel dentro de la región de búsqueda se procede a calcular el minimo MSE de tal forma que la region RS' con el minimo MSE sera llamada RS*, tal que:
	\begin{equation}
		RS^* = \arg \min{RS'}\{\text{MSE}(\text{RS},\text{RS'}) | \text{RS'} \in \text{WS}\},
	\end{equation}		
	el cual será el cuadro donde la ventana de soporte se desplazó en el cuadro $t+1$, con esto se obtiene el píxel $(x^*,y^*)$ que corresponde al centro de la ventana obtenida en el proceso anterior.
	
	Para calcular el desplazamiento en el cuadro $t$ de $(x,y)$ a $(x^*,y^*)$, se procede a realizar la resta de los ejes. De tal forma que:
	\begin{align}
		\Delta x^{t} &= x-x^*,\\ 
		\Delta y^{t} &= y-y^*.
	\end{align}
		Donde $ \Delta x^*$ y $ \Delta y^*$ son componentes del ``Rayo de soporte'', y definimos el $j$-esimo ``Rayo de soporte'' como:
	\begin{equation}
		\rho_j = \{(\Delta x_j^{t}, \Delta y_j^{t})~| \forall t\},
	\end{equation}		
	donde j es el índice que equivale a enumerar los píxeles de la imagen de la forma:
	\begin{equation}
		j = Col*(y-1) + x,
	\end{equation}
	donde $Col$ es el numero columnas de píxeles que contiene la imagen.
	
	Los ``Rayos de soporte'' son la estructura básica de los ``Rayos de flujo'', dado que al juntar todos los desplazamientos del píxel $(x,y)$ a lo largo de los cuadros del vídeo, se obtiene un conjunto de variaciones de movimientos de estos. Este conjunto es definido como el ``Rayo'' o micro-descriptor.
	\begin{equation}
		R(x,y)	 = \{\rho_1(x,y), \rho_2(x^*,y^*), \rho_3(x^{**},y^{**}), ... \}
	\end{equation}
		Donde ($x^{**}$,$y^{**}$) es el píxel al cual se desplazo ($x^{*}$,$y^{*}$) en el cuadro $t$+2. El desplazamiento de los ``Rayos'' puede ser visto en la Figura~\ref{algoritmo:fig:normalizacion}.
		
		%%HABLAR DE ventana de soporte, ventana de busqueda MSE
		
	\subsection{Normalización de rayos}
	\label{algoritmo:normalizacion}
	Luego de obtener el total de micro-descriptores es necesario poder llevar todos los rayos al mismo espacio vectorial, esto debido a que el tamaño de cada conjunto depende de la cantidad de cuadros $T$ del vídeo. Para este proceso se introduce una variable muy importante para el algoritmo llamada $N$, esta sera la encargada de comandar el proceso de normalización, de tal forma que se obtiene una razón de normalización
	\begin{equation}
		Razon = \frac{T}{N},
	\end{equation}
	que permite relacionar la cantidad de ``Rayos de soporte'' $\rho_j$ del ``Rayo'' $R(x,y)$ original formaran parte de los $\rho_j '$ de $R(x,y)'$' normalizado. Este proceso puede ser visualizado en la Figura~\ref{algoritmo:fig:normalizacion}.
	
	\begin{figure}[bt]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/normalizacion_de_rayos.png}
  		\caption{Representación y Normalización de rayos.}
  		\label{algoritmo:fig:normalizacion}
	\end{figure}	

	
\newpage	
\section{Creación de macro-descriptores}
\label{sec:macro-descriptores}
El proceso de creación de macro-descriptores es el proceso final de la extracción de características de los vídeos. Luego de obtener un extenso conjunto de ``Rayos'' para cada uno de los vídeos, es necesario poder crear grupos de ``Rayos'', los cuales puedan representar de mejor manera el espacio ya normalizado. Para esto se utilizan técnicas de ``clustering'' o agrupamiento. El proceso de Creacion de maro-descriptores puede ser visto en las Figuras~\ref{algoritmo:fig:macro_descriptores:entrenamiento} y~\ref{algoritmo:fig:macro_descriptores:clasificacion}

	\begin{figure}[bt]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/Extractor_macrodescriptores_entrenamiento.png}
  		\caption{Proceso de creación de macro-descriptores en la fase de entrenamiento.}
  		\label{algoritmo:fig:macro_descriptores:entrenamiento}
	\end{figure}	
	
	
	\begin{figure}[bt]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/Extractor_macrodescriptores_clasificacion.png}
  		\caption{Proceso de creación de macro-descriptores en la fase de clasificación.}
  		\label{algoritmo:fig:macro_descriptores:clasificacion}
	\end{figure}	

	\subsection{Bag of words}
	\label{algoritmo:bow}
		Esta es una técnica dependiente de la cantidad de palabras $K$ o ``words'' que se introduzcan a la bolsa. Esta técnica permite armar $K$ grupos representados por un centroide o cluster llamado $C_k$ como se puede ver en la Figura~\ref{algoritmo:fig:bow}. Estos clusters son los puntos de referencia de cada uno de sus grupos. Para saber a cual de estos $k$ centroides pertenece un ``Rayo'' $R(x,y)$, es necesario calcular el
		\begin{equation}
  			\label{algoritmo:eq:dist}
			k^* = \arg \min\{dist(R(x,y),C_k)\},
		\end{equation}
		donde la función de distancia $dist()$ a utilizar depende de la instancia del algoritmo.

	\begin{figure}[tb]
		\centering
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/bow_solo.png}
  		\caption{Construcción del Bag of Words.}
  		\label{algoritmo:fig:bow}
	\end{figure}	

	\subsection{Creación de macro-descriptores}
	\label{algoritmo:crea_macro-descriptores}
	Luego de tener etiquetado cada uno de los ``Rayos'' $R(x,y)$ con su centroide respectivo, se procede a crear el macro-descriptor de cada uno de los vídeos.	 Esto se realiza creando un histograma de tamaño $K$ para cada uno de las regiones de interés ${ROI}_{i}^{t}$ del vídeo, de tal forma que en este histograma se tenga presente la frecuencia de cada uno de los clusters encontrados en la creación del ``Bag of Words''.
	\begin{equation}
  			\label{algoritmo:eq:hist}
  			D_i(k) = \sum_{(x,y)}^{} \delta (R(x,y),k), \forall k,
	\end{equation}
	
	\begin{equation}
		\label{algoritmo:eq:fun_hist}
		 \delta (R(x,y),k) = \left \{ \begin{matrix} 1 & \mbox{si }R(x,y)~\in~C_k
\\ 0 & otro~caso\end{matrix}\right. 
	\end{equation}

%		 \left \{ \begin{matrix} 1 & \mbox{si }R(x,y)\mbox{ \in C_k} \\ 0 & \mbox{}\mbox{de otra forma}\end{matrix}\right. 		

	
	Luego de obtener dichos descriptores por región, se procede a concatenar cada uno de los histogramas pertenecientes al mismo vídeo de la siguiente forma:
	\begin{equation}
		\mathds{D} = \cat_{i = 1}^{I} D_i, \forall i,
	\end{equation}	   
   este proceso puede ser visto en la Figura~\ref{algoritmo:fig:macro-descriptores}. El resultado de esta concatenación es el macro-descriptor del vídeo seleccionado.
	\begin{figure}[bt]
		\centering
  		\label{algoritmo:fig:macro-descriptores}
    		\includegraphics[width=1\textwidth]{Figuras/Diagramas/macro-descriptor.png}
  		\caption{Construcción del macro-descriptor.}
	\end{figure}	

	En el proceso clasificación, no se recalculan los centroides para un nuevo vídeo, ya que, se guarda el modelo que contiene el resultado del Bag of Words, y se procede a calcular~(\ref{algoritmo:eq:dist}), para cada uno de los ``Rayos'' $R(x,y)$ obtenidos en el proceso de extracción de micro-descriptores. Luego de esto al igual que en el proceso de entrenamiento se crea el macro-descriptor con el mismo método.
	
	
\section{Entrenamiento y clasificación}
\label{sec:clasificacion}
Ultima etapa del algoritmo, se dedicada a la segmentación del espacio vectorial formado por los macro-descriptores. Para este proceso se utilizara las Maquinas de Vectores de Soporte explicadas en la Sección~\ref{sec:rec_patrones}. Estas máquinas, se utilizan para entrenar el modelo que luego es el que permite clasificar las nuevas entradas de vídeo. 
Para poder probar la efectividad del clasificador se utilizaran técnicas de validación cruzada o $k$-fold cross-validation (Por sus siglas en inglés). Esta técnica consiste en dividir el conjunto de datos de datos en dos grupos, uno de entrenamiento y uno de prueba, $k$ veces. Se mostraran los resultados de esta técnica en la Capitulo~\ref{ch:exp_result}.


	\subsection{Entrenamiento}
	\label{algoritmo:entrenamiento}
		Luego de que el conjunto de datos de entrenamiento pasa por todas las etapas anteriores del algoritmo, se tiene para cada uno de los vídeos un macro-descriptor compuesto por la concatenación de los histogramas de de cada una de las regiones de interés y una etiqueta que indica a que clase pertenecen. Este conjunto de descriptores y las etiquetas son utilizados por las Maquinas de Vectores de Soporte para la creación de un modelo de clasificación, el permite poder etiquetar nuevas entradas, este proceso puede ser visto en la Figura~\ref{algoritmo:fig:entrenamiento}.
		
	\begin{figure}[bt]
		\centering
  		\label{algoritmo:fig:entrenamiento}
    		\includegraphics[width=0.7\textwidth]{Figuras/Diagramas/Entrenamiento.png}
  		\caption{Entrenamiento del clasificador.}
	\end{figure}	
		
		
	\subsection{Clasificación}
	\label{algoritmo:clasificacion}
		Ya teniendo el modelo entrenado resultante de la etapa de clasificación, este es utilizado para la clasificación de nuevas entradas sin etiquetar, esto con la misión de poder asignar una etiqueta al nuevo descriptor, este proceso puede ser visto en la Figura~\ref{algoritmo:fig:clasificacion}. En esta etapa se puede medir cual es la precision del algoritmo, esta medición sera mayormente abordada en el Capitulo~\ref{ch:exp_result}.
	
	\begin{figure}[bt]
		\centering
  		\label{algoritmo:fig:clasificacion}
    		\includegraphics[width=0.7\textwidth]{Figuras/Diagramas/Clasificacion.png}
  		\caption{Clasificador utilizando el modelo creado para clasificar nuevas entradas.}
	\end{figure}	
		
	
	
	
	
	