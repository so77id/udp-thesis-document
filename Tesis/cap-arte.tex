\chapter[Estado del arte]{Estado del arte}
\label{ch:estado_del_arte}

\section{Reconocimiento de patrones}
\label{sec:rec_patrones}
	No existe una definición universalmente aceptada para el Reconocimiento de Patrones (RP). Esta puede recibir distintas definiciones dependiendo de la disciplina sobre la cual se quiere aplicar. Algunos autores como Duda \etal~\cite{Duda1973} definen el reconocimiento de patrones, junto con reconocimiento de máquina como un campo preocupado de las regularidades del ruido en entornos complejos. Sergios Theodoridis~\cite{Theodoridis2008} lo define como una disciplina científica que apunta a la clasificación de objetos dentro de un conjunto de categorías o clases, y también como una parte integral del sistema de inteligencia de la máquina construida para la toma de decisiones. González y Thomason~\cite{Gonzalez1978} define el RP como la clasificación de la entrada de datos a través de la extracción de importantes características de un conjunto de estos con ruido. 

\begin{figure}[b]
  \centering
   \includegraphics[width=1\textwidth]{Figuras/Diagramas/estado_del_arte/Reconocimiento_de_patrones.png}
  \caption{Arquitectura básica de un sistema de reconocimiento de patrones.}
  \label{art:fig:arquitectura}
\end{figure}


En este trabajo se define el reconocimiento de patrones como un área de la Inteligencia Artificial (IA) enfocada en la extracción de características de un conjunto de imágenes o vídeos, las cuales definen los patrones que serán utilizados para la creación de un modelo que permita clasificar nuevas entradas. Podemos describir este procedimiento en tres procesos como se puede ver en la Figura~\ref{art:fig:arquitectura}: adquisición de datos, extracción de características y toma de decisiones. 

	\textbf{Adquisición de datos.} Este procedimiento es el encargado de sensar la información del mundo real, para esto se utilizan distintos sensores dependiendo del área al cual se quiera aplicar el RP. Estos sensores tienen distintas respuestas dependiendo de su calidad o las variables del medio ambiente como la luminosidad, ruido ambiental, \etc. Para este trabajo nos enfocaremos en los sensores de imágenes instalados en las cámaras que capturan los vídeos que luego serán clasificados por nuestro sistema.
	
	\textbf{Extracción de características.} Primer proceso en el cual interviene la maquina, tiene como objetivo transformar las señales adquiridas por la etapa anterior a una representación vectorial capas de ser interpretada por los clasificadores para la toma de decisiones. Este procedimiento es el que mas varia a la hora de construir sistemas de reconocimiento de patrones, esto debido a que existe una gran variación de la implementación a realizar dependido del problema que se requiera atacar. Para esta etapa existen distintos métodos que se pueden utilizar para resolver el problema propuesto, estos serán mayormente estudiados en la Sección~\ref{sec:type_fe}.
	
	\textbf{Toma de decisiones.} Ultima etapa del RP, esta se encarga de realizar la toma de decisiones utilizando las características extraídas en la etapa anterior. Para esto podemos dividir este bloque en dos sub-procesos, entrenamiento y clasificación. El entrenamiento consiste en tomar una gran cantidad de datos ya clasificados anteriormente de forma correcta por algún experto en el tema, y utilizar estos datos para poder crear un modelo el cual divida el espacio vectorial representado por las características de cada uno de los datos de entrenamiento. La clasificación consiste en utilizar el modelo creado en la etapa de entrenamiento para poder clasificar nuevas entradas no tomadas encuentra en el entrenamiento. Para la etapa de creación del modelo se pueden utilizar distintas técnicas que permiten dividir el espacio en distintas regiones dependiendo de las etiquetas o clases a las cuales se requiera clasificar, tales como: Redes bayesianas, técnicas de clustering, redes neuronales, Modelos Ocultos de Markov (HMM por sus siglas en inglés). Para el desarrollo de nuestro método utilizaremos las Maquinas de Soporte Vectorial~\cite{Cortes1995,Hearst1998}, las cuales permiten realizar una clasificación de muchas clases en un mismo espacio vectorial al mismo tiempo. 


	\textbf{Máquinas de vectores de soporte}
	\label{sec:svm}
	Las Máquinas de Vectores de Soportes (SVM sus siglas en inglés) son herramientas fundamentales en sistemas de aprendizaje automático, se basan en  implementar reglas de decisión complejas, por medio de un kernel que permite mapear los puntos de entrenamiento a un espacio de mayor dimensión. Estas máquinas son utilizadas para la clasificación y análisis de regresión permitiendo generar un modelo de predicción dado un conjunto de datos de entrada, y posteriormente utilizar este modelo para clasificar nuevos datos.
La idea del SVM es solucionar un problema de clasificación de dos clases mediante una barrera de decisión. Estos métodos evolucionaron con el tiempo y se utilizan para poder solucionar el problema de clasificación de múltiples clases.

Para efectos de este trabajo, SVM es utilizado para poder generar el modelo final que permita clasificar las seis expresiones faciales canónicas, utilizando los descriptores obtenidos luego de la extracción de características.

\section{Reconocimiento de expresiones faciales}
\label{sec:fer}
Las expresiones faciales constituyen una guía básica en la interacción social. Por ello, las alteraciones en su expresión o reconocimiento suponen una importante limitación para la comunicación. Ya que las expresiones del rostro son la variable que más se observa para obtener información de las emociones de nuestros interlocutores; si bien es cierto que tenemos un elevado control sobre nuestra expresividad facial, diversos estudios han demostrado que, cuando una persona está utilizando una expresión facial no acorde con su verdadero estado de ánimo, en su cara aparecen durante breves momentos señales de la expresión verdadera que a menudo pasan desapercibidas por las demás personas, estas se conocen como expresiones faciales universales.


\subsection{Expresiones faciales universales}
\label{sec:type_fe}

Las expresiones faciales del rostro humano tienen una infinidad de posibles variaciones que permiten la comunicación, regulación y adecuación de las emociones en el contexto social.

Darwin afirma en uno de  sus estudios publicado a fines del siglo XIX, que nosotros no podemos entender las expresiones emocionales humanas sin entender las expresiones emocionales de los animales, para esto, él argumenta que nuestras expresiones son determinadas en gran parte por nuestra evolución~\cite{Darwin1956,Darwin1998}. En la actualidad Paul Ekman, psicólogo pionero en el estudio de las emociones y su relación con la expresión facial, propone que las expresiones faciales están compuestas por micro-expresiones muy breves, que duran sólo una fracción de segundo. Estas se producen cuando una persona ya sea deliberadamente o inconscientemente esconde un sentimiento~\cite{Ekman1981}.

Ekman define que existen seis expresiones universales: 

\begin{enumerate}
	\item Alegría (Happiness) : se produce mediante la contracción del músculo que va del pómulo al labio superior y del orbicular que rodea al ojo. También se elevan las mejillas. 
	\item Asco (Disgust): Existe una ligera contracción del músculo que frunce la nariz y estrecha los ojos. El gesto de la nariz arrugada es simultáneo al de la elevación del labio superior. 
	\item Ira (Anger): Se produce con una mirada fija, cejas juntas y hacia abajo, y existe una tendencia a apretar los dientes. 
	\item Miedo (Fear): Es la expresión que se presenta después del sorpresa. Donde se observa los párpados superiores elevados al máximo e inferiores tensos. Las cejas levantadas se acercan y los labios se alargan hacia atrás. 
	\item Sorpresa (Surprise): Los párpados superiores suben, pero los inferiores no están tensos, la mandíbula suele caer. 
	\item Tristeza (Sadness): se manifiesta cuando los párpados superiores caen y las cejas se angulan hacia arriba. El entrecejo se arruga y los labios se estiran de forma horizontal.
\end{enumerate}


\subsection{Métodos de reconocimiento de expresiones faciales}
El reconocimiento de expresiones faciales lo podemos dividir en dos grandes tipos, según las características que se enfocan: la extracción de características geométricas y de características de apariencia, ver ~\cite{Pantic2000,Zeng2009} para mas información acerca de los tipos de métodos de reconocimiento de expresiones faciales. A su vez cada una de estas subdivisiones tiene métodos que ayudan a reconocer las expresiones en imágenes o en vídeos.

\subsubsection{Métodos basados en características geométricas}
\label{sec:met_geo}
Los métodos geométricos se basan en detectar formas y regiones de la cara que se esta procesando, así como puntos de características faciales (\eg ojos, comisuras de la boca, \etc). 
Luego de encontrar las regiones importantes del rostro que se esta analizando se procede a realizar la clasificación. Los métodos geométricos al ser aplicados sobre imágenes dinámicas o vídeos, realizan el procedimiento de encontrar cada una de estas regiones importantes del rostro que aportan la mayor cantidad de información, y luego se realiza el seguimiento a lo largo de la secuencia de cuadros del vídeo. Una de las grandes ventajas de estos métodos, es que al ser enfocado en encontrar una cantidad determinada de puntos, son algoritmos muy rápidos y de fácil aplicación a sistemas de reconocimiento en tiempo real. A su vez no son tan robustos como los basados en apariencia.


\subsubsection{Métodos basados en características de apariencia}
\label{sec:met_apa}
Se basan en detectar los movimientos de las texturas en la imagen, en el caso de imágenes con rostros humanos, cambios o deformaciones en la piel (\eg arrugas, protuberancias, surcos, \etc). En si son métodos que no se basan en encontrar ciertos puntos específicos del rostro, sino que encuentran regiones importantes de las texturas a analizar. Existen distintas aplicaciones de estos métodos, tanto sobre imágenes estáticas como para vídeo o imágenes dinámicas.  

	\subsubsection{Métodos sobre imágenes}
	\label{sec:met_imagen}
		Son métodos enfocados en encontrar ciertas regularidades existentes entre las texturas de la imagen a analizar, ejemplos:

		\subsubsection{Patrones binarios locales (LBP)}
		\label{sec:lbp}
		Método introducido por Wang y He~\cite{Wang1990}, consiste en realizar una codificación del píxel de interés con respecto a los valores de sus vecinos. En simples palabras se realiza un proceso de máscara en el cual se restan los píxeles del vecindario con el píxel central, si la resta es negativa o cero se asigna un cero en la posición del vecino, por el contrario si es positiva se asigna un uno. Luego de esto, se realiza una concatenación de los vecinos y se obtiene un código binario que es transformado a base 10. Dicho número es asignado como nuevo valor del píxel visitado~\cite{Ojala1994,Ojala2002,Ahonen2004,Shan2009}.

Luego de realizar el proceso en todos los píxeles se procede a realizar un histograma de los valores el cual es definido como el descriptor de la imagen, siendo este utilizado una para posterior clasificación.

Otros métodos que utilizan LBP antes de la obtención del descriptor dividen la imagen en $n$ secciones de igual o distintas áreas, y realizan el cálculo del histograma para cada una de estas secciones. Luego concatenan cada uno de los histogramas en un orden específico y se obtiene un macro descriptor más detallado de la imagen~\cite{Ahonen2006}.

		\textbf{Local direccional numbers}
		\label{sec:lnd}

	\subsubsection{Métodos sobre imágenes dinámicas}	
	\label{sec:met_videos}
	Para estos métodos se introduce la variable temporal $t$, la cual es la encargada de regir el movimiento de los píxeles a lo largo del tiempo, al igual que los métodos sobre imágenes estáticas, estos métodos resuelven el problema siendo planteado de la misma forma, pero ahora dependiendo el modelo a utilizar es como se soluciona el problema de la variable $t$.

		\textbf{Volume Local Binary Patterns.}
		\label{sec:vlbp}
		Método introducido por Zhao y Pietikäinen~\cite{Zhao2006}, basado en LBP para imágenes dinámicas, el cual se basa en tres variables: $L$ la cantidad de cuadros que entran en la creación del patrón, $P$ el tamaño del vecindario a seleccionar y $R$ el radio del cual se escogen los vecinos. 
El método VLBP consiste en realizar una codificación basada en LBP, ahora incluyendo la variable temporal $L$ que indica desde qué cuadro se comienza a realizar la resta del píxel seleccionado con el central.
Éste es un proceso muy costoso debido a que mientras mayor sea la cantidad de vecinos a seleccionar, mayor será la cantidad de dígitos binarios, lo cual implica un mayor espectro de números resultantes en la codificación~\cite{Zhao2007a}, \cite{Zhao2007}.

		\textbf{Local Binary Patterns-Three Ortogonal Planes}
		\label{sec:lbp-top}
		 Es un método basado en LBP para imágenes dinámicas, consiste en crear tres planos ortogonales que se intersectan en el píxel de interés, siendo estos el plano $XY$, $XT$, y $YT$ (cuadro actual, movimiento temporal en $X$ y en $Y$ respectivamente). 

Para poder obtener el patrón de la imagen se realiza el mismo proceso de resta con los píxeles del vecindario seleccionado, pero a diferencia de los métodos estáticos que solo se realizan en el plano $XY$, este también se realiza para los planos $XT$ e $YT$.\@ Con esto se obtiene un histograma para cada plano, los cuales son concatenados y forman el macro descriptor de la imagen~\cite{Zhao2007}.


\section{Reconocimiento y corrección de rostros}
\label{sec:rec_rostros}


	\subsection{Framework Viola-Jones}
	\label{sec:viola-jones}
	Introducido por Viola y Jones~\cite{jones2003fast}, es un método que utiliza clasificación en cascada, y un entrenador de clasificadores débiles basado en AdaBoost. Este algoritmo consiste en subdividir la imagen a analizar en pequeñas sub-imágenes, las cuales son entregadas a una serie de clasificadores (etapas), cada uno con un conjunto de características visuales. El método consiste en que cada sub-imagen es evaluada por la serie de clasificadores, si en una es encontrado un rostro, esta sub-imagen es entregada al siguiente clasificador, el cual revisa de forma mas rigurosa la imagen. Si la imagen es aceptada por todos los clasificadores, esta esa clasificada como un rostro.
	
	\subsection{Corrección de movimiento rígido}
	\label{sec:rigid}
	Los métodos de corrección de movimiento rígido consisten en utilizar técnicas de rotación y traslación de regiones de la imagen, esto para poder ajustar el movimiento de todos los cuadros del vídeo sobre una región especifica. Este tipo de corrección no alteran el tamaño de la imagen, solo su ubicada y el ángulo su rotación.

\section{Optical flow}
\label{sec:optical_flow}

\section{Bag of words}
\label{sec:bag_of_words}

	\subsection{K-means}
	\label{sec:k-means}
	
	\subsection{Métricas de distancia}
	\label{sec:matricas_de_distancia}